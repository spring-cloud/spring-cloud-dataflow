[[getting-started]]
= Getting started

[partintro]
--
If you're just getting started with Spring Cloud Data Flow, this is the section
for you! Here we answer the basic "`what?`", "`how?`" and "`why?`" questions. You'll
find a gentle introduction to Spring Cloud Data Flow along with installation instructions.
We'll then build our first Spring Cloud Data Flow application, discussing some core principles as
we go.
--

[[getting-started-system-requirements]]
== System Requirements

You need Java installed (Java 7 or better, we recommend Java 8) and to build you need to have Maven installed as well.

You also need to have link:http://redis.io/[Redis] installed and running if you plan on running a local system, or to run the included tests.

== Running behind proxy

If you run the Data Flow Server behind the proxy, then you can update the proxy configuration properties for Aether resolver either in `dataflow-server.yml` as:

```
aether:
  proxy:
    protocol:
    host:
    port:
    auth:
      username:
      password:
```
By default, the protocol is set to use `http`. You can omit the auth properties if the proxy doesn't need username/password.
These properties can also be specified as command line arguments like `--aether.proxy.host=<?> --aether.proxy.port=<?>` to the Data Flow server.

[[getting-started-deploying-spring-cloud-dataflow]]
== Deploying Spring Cloud Data Flow

=== Deploying 'local'

[start=1]
1. download the Spring Cloud Data Flow Server and Shell apps:

```
wget http://repo.spring.io/milestone/org/springframework/cloud/spring-cloud-dataflow-server-local/1.0.0.BUILD-SNAPSHOT/spring-cloud-dataflow-server-local-1.0.0.BUILD-SNAPSHOT.jar
wget http://repo.spring.io/milestone/org/springframework/cloud/spring-cloud-dataflow-shell/1.0.0.BUILD-SNAPSHOT/spring-cloud-dataflow-shell-1.0.0.BUILD-SNAPSHOT.jar
```
[start=2]
1. launch the Data Flow Server:

```
$ java -jar spring-cloud-dataflow-server-local-1.0.0.BUILD-SNAPSHOT.jar
```
By default, this will start the local deployer that is `out-of-process`. If you want to use `in-process` deployer then

```
$ java -jar spring-cloud-dataflow-server-local-1.0.0.BUILD-SNAPSHOT.jar --deployer.out-of-process=false
```

[start=3]
1. launch the shell:

```
$ java -jar spring-cloud-dataflow-shell-1.0.0.BUILD-SNAPSHOT.jar
```

If the Data Flow server and shell are not running on the same host, point the shell to the Data Flow server

```
server-unknown:>dataflow config server http://dataflow-server.cfapps.io
Successfully targeted http://dataflow-server.cfapps.io
dataflow:>
```

You can now use the shell commands to list modules and create streams.  For example

```
dataflow:>stream create --name httptest --definition "http --server.port=9000 | log" --deploy

dataflow:> http post --target http://localhost:9000 --data "hello world"
```

Look to see if data ended up in log files under the /tmp directory.

[[getting-started]]
= Getting started

[partintro]
--
If you're just getting started with Spring Cloud Data Flow, this is the section
for you! Here we answer the basic "`what?`", "`how?`" and "`why?`" questions. You'll
find a gentle introduction to Spring Cloud Data Flow along with installation instructions.
We'll then build our first Spring Cloud Data Flow application, discussing some core principles as
we go.
--

[[getting-started-system-requirements]]
== System Requirements

You need Java installed (Java 7 or better, we recommend Java 8) and to build you need to have Maven installed as well.

You also need to have link:http://redis.io/[Redis] installed and running if you plan on running a local system, or to run the included tests.

[[getting-started-deploying-spring-cloud-dataflow]]
== Deploying Spring Cloud Data Flow

=== Deploying 'local'

[start=1]
1. download the Spring Cloud Data Flow Admin and Shell apps:

```
wget http://repo.spring.io/milestone/org/springframework/cloud/spring-cloud-dataflow-admin-local/1.0.0.M2/spring-cloud-dataflow-admin-local-1.0.0.M2.jar
wget http://repo.spring.io/milestone/org/springframework/cloud/spring-cloud-dataflow-shell/1.0.0.M2/spring-cloud-dataflow-shell-1.0.0.M2.jar
```
[start=2]
2. launch the admin:

```
$ java -jar spring-cloud-dataflow-admin-local-1.0.0.M2.jar
```

[start=3]
3. launch the shell:

```
$ java -jar spring-cloud-dataflow-shell-1.0.0.M2.jar
```

If the admin and local are not running onthe same host, point the shell to the admin server

```
server-unknown:>admin config server http://s-c-dataflow-admin.cfapps.io
Successfully targeted http://s-c-dataflow-admin.cfapps.io
dataflow:>
```

You can now use the shell commands to list modules and create streams.  For example

```
dataflow:>stream create --name httptest --definition "http --server.port=9000 | log" --deploy

dataflow:> http post --target http://localhost:9000 --data "hello world"
```

Look to see if data ended up in log files under the /tmp directory.
